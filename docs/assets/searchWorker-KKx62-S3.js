(function(){"use strict";const O="sermon-search-cache",g="text_chunks";function C(){return new Promise((h,a)=>{const e=indexedDB.open(O,2);e.onerror=()=>a(e.error),e.onsuccess=()=>h(e.result),e.onupgradeneeded=r=>{const n=r.target.result;n.objectStoreNames.contains(g)||n.createObjectStore(g,{keyPath:"chunkIndex"}),n.objectStoreNames.contains("cache_meta")||n.createObjectStore("cache_meta",{keyPath:"key"})}})}async function R(h){try{const a=await C();return new Promise(e=>{const n=a.transaction(g,"readonly").objectStore(g),c=new Map;let u=h.length;if(u===0){e(c);return}h.forEach(m=>{const i=n.get(m);i.onsuccess=()=>{i.result?.data&&c.set(m,i.result.data),--u===0&&e(c)},i.onerror=()=>{--u===0&&e(c)}})})}catch{return new Map}}async function B(h){try{const a=await C();return new Promise(e=>{const r=a.transaction(g,"readwrite"),n=r.objectStore(g),c=Date.now();for(const[u,m]of h.entries())n.put({chunkIndex:u,data:m,cachedAt:c});r.oncomplete=()=>e(!0),r.onerror=()=>e(!1)})}catch{return!1}}async function D(h){const{term:a,variations:e,rawRegex:r,options:n,totalChunks:c,apiPrefix:u}=h,{wholeWords:m=!0}=n||{};let i;const y=Object.create(null);if(r&&String(r).trim())try{i=new RegExp(r,"gi")}catch(t){self.postMessage({type:"error",message:"Invalid regex: "+t.message});return}else{const t=Array.isArray(e)?e.map(s=>String(s).trim()).filter(Boolean):String(e||"").split(",").map(s=>s.trim()).filter(Boolean),o=s=>/[\\\(\)\[\]\|\^\$\.\*\+\?]/.test(s),d=s=>String(s).replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),l=[a,...t].map(s=>o(s)?s:d(s));m?i=new RegExp(`\\b(${l.join("|")})\\b`,"gi"):i=new RegExp(`(${l.join("|")})`,"gi")}const w=Object.create(null),_=50,E=Array.from({length:c},(t,o)=>o);self.postMessage({type:"progress",message:"Checking cache...",percent:0});const $=await R(E),k=$.size,M=E.filter(t=>!$.has(t));self.postMessage({type:"progress",message:`Found ${k}/${c} chunks in cache`,percent:0,cached:k,total:c});let f=0;for(const[t,o]of $.entries()){for(const d of o)try{const l=d.text?d.text.match(i):null;if(l&&l.length>0){w[d.id]=(w[d.id]||0)+l.length;for(const s of l){const x=s.toLowerCase();y[x]=(y[x]||0)+1}}}catch{}f++,f%20===0&&self.postMessage({type:"progress",message:`Searching cached: ${f}/${k}`,percent:Math.round(f/c*100)})}if(M.length>0){self.postMessage({type:"progress",message:`Downloading ${M.length} uncached chunks...`,percent:Math.round(k/c*100)});const t=new Map;for(let o=0;o<M.length;o+=_){const l=M.slice(o,o+_).map(b=>fetch(`${u}text_chunk_${b}.json`).then(p=>p.ok?p.json():[]).then(p=>({idx:b,data:p})).catch(()=>({idx:b,data:[]}))),s=await Promise.all(l);for(const{idx:b,data:p}of s){p.length>0&&t.set(b,p);for(const j of p)try{const S=j.text?j.text.match(i):null;if(S&&S.length>0){w[j.id]=(w[j.id]||0)+S.length;for(const A of S){const I=A.toLowerCase();y[I]=(y[I]||0)+1}}}catch{}f++}const x=Math.round(f/c*100);self.postMessage({type:"progress",message:`Scanning: ${x}% (${f}/${c})`,percent:x})}t.size>0&&B(t).then(()=>{self.postMessage({type:"cached",count:t.size})})}const P=Object.entries(y).map(([t,o])=>({term:t,count:o})).sort((t,o)=>o.count-t.count);self.postMessage({type:"complete",counts:Object.entries(w),matchedTerms:P,regexSource:i.source})}self.onmessage=async h=>{const{type:a,...e}=h.data;if(a==="search")await D(e);else if(a==="clearCache")try{const n=(await C()).transaction([g,"cache_meta"],"readwrite");n.objectStore(g).clear(),n.objectStore("cache_meta").clear(),n.oncomplete=()=>self.postMessage({type:"cacheCleared"})}catch{self.postMessage({type:"cacheCleared"})}}})();
